{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b48a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\fully_annotated_image.jpg'\n",
    "reference_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\original_image.jpg'\n",
    "\n",
    "# Load the fully annotated image and the reference image\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "reference_image = cv2.imread(reference_image_path)\n",
    "\n",
    "# Assuming you have annotation masks for the fully annotated image and reference image\n",
    "fully_annotated_mask_path = \"path/to/fully_annotated_mask.png\"\n",
    "reference_mask_path = \"path/to/reference_mask.png\"\n",
    "\n",
    "# Load the annotation masks as grayscale images\n",
    "fully_annotated_mask = cv2.imread(fully_annotated_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "reference_mask = cv2.imread(reference_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Threshold the masks to obtain binary segmentation\n",
    "_, fully_annotated_binary_mask = cv2.threshold(fully_annotated_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "_, reference_binary_mask = cv2.threshold(reference_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary masks\n",
    "fully_annotated_contours, _ = cv2.findContours(fully_annotated_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "reference_contours, _ = cv2.findContours(reference_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate over the fully annotated contours and transfer the annotations to the corresponding regions in the reference image\n",
    "for fully_annotated_contour in fully_annotated_contours:\n",
    "    # Find the bounding rectangle for the fully annotated contour\n",
    "    x, y, w, h = cv2.boundingRect(fully_annotated_contour)\n",
    "\n",
    "    # Extract the corresponding region in the reference image\n",
    "    reference_region = reference_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the annotation or label to the reference region\n",
    "    # You can perform any desired operation here, such as refining boundaries, aligning annotations, or modifying labels\n",
    "\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the reference image\n",
    "    reference_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "# Overlay the transferred and adjusted annotations onto the partially annotated image\n",
    "partially_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\partially annotated image.jpg'\n",
    "transferred_annotations_path = r\"C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\transferred_annotations.jpg\"\n",
    "\n",
    "# Load the partially annotated image and the transferred annotations\n",
    "partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "transferred_annotations = cv2.imread(transferred_annotations_path)\n",
    "\n",
    "# Create a blank image with the same size as the partially annotated image\n",
    "transferred_annotations = np.zeros_like(partially_annotated_image)\n",
    "\n",
    "# Validate the sizes of partially_annotated_image and transferred_annotations\n",
    "if partially_annotated_image.shape[:2] != transferred_annotations.shape[:2]:\n",
    "    raise ValueError(\"Sizes of partially annotated image and transferred annotations do not match\")\n",
    "\n",
    "# Overlay the transferred annotations onto the partially annotated image\n",
    "combined_image = cv2.addWeighted(partially_annotated_image, 1, transferred_annotations, 0.5, 0)\n",
    "\n",
    "# Display or save the combined image\n",
    "cv2.imshow(\"Combined Image\", combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "874f12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "original_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\original_image.jpg'\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\fully_annotated_image.jpg'\n",
    "\n",
    "# Load the original image and the fully annotated image\n",
    "original_image = cv2.imread(original_image_path)\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "\n",
    "# Assuming you have annotation masks for the fully annotated image\n",
    "fully_annotated_mask_path = \"path/to/fully_annotated_mask.png\"\n",
    "\n",
    "# Load the annotation mask as a grayscale image\n",
    "fully_annotated_mask = cv2.imread(fully_annotated_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Threshold the mask to obtain binary segmentation\n",
    "_, fully_annotated_binary_mask = cv2.threshold(fully_annotated_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary mask\n",
    "fully_annotated_contours, _ = cv2.findContours(fully_annotated_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a blank image with the same size as the original image\n",
    "partially_annotated_image = np.zeros_like(original_image)\n",
    "\n",
    "# Iterate over the fully annotated contours and draw them on the partially annotated image\n",
    "for fully_annotated_contour in fully_annotated_contours:\n",
    "    cv2.drawContours(partially_annotated_image, [fully_annotated_contour], -1, (0, 255, 0), thickness=cv2.FILLED)\n",
    "\n",
    "# Overlay the fully annotated image on the partially annotated image\n",
    "combined_image = cv2.addWeighted(original_image, 0.5, partially_annotated_image, 0.5, 0)\n",
    "\n",
    "# Display or save the combined image\n",
    "cv2.imshow(\"Partially Annotated Image\", combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "492d8b19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to load the annotation mask. Please check the file path and format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Check if the mask was loaded successfully\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fully_annotated_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load the annotation mask. Please check the file path and format.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Resize the mask to match the dimensions of the fully annotated image\u001b[39;00m\n\u001b[0;32m     22\u001b[0m resized_mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(fully_annotated_mask, (fully_annotated_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], fully_annotated_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to load the annotation mask. Please check the file path and format."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\fully_annotated_image.jpg'\n",
    "fully_annotated_mask_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\fully_annotated_mask.png'\n",
    "\n",
    "# Load the fully annotated image\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if fully_annotated_image is None:\n",
    "    raise ValueError(\"Failed to load the fully annotated image. Please check the file path and format.\")\n",
    "\n",
    "# Load the annotation mask\n",
    "fully_annotated_mask = cv2.imread(fully_annotated_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if the mask was loaded successfully\n",
    "if fully_annotated_mask is None:\n",
    "    raise ValueError(\"Failed to load the annotation mask. Please check the file path and format.\")\n",
    "\n",
    "# Resize the mask to match the dimensions of the fully annotated image\n",
    "resized_mask = cv2.resize(fully_annotated_mask, (fully_annotated_image.shape[1], fully_annotated_image.shape[0]))\n",
    "\n",
    "# Threshold the mask to obtain binary segmentation\n",
    "_, fully_annotated_binary_mask = cv2.threshold(resized_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary mask\n",
    "fully_annotated_contours, _ = cv2.findContours(fully_annotated_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a blank mask with the same size as the fully annotated image\n",
    "mask = np.zeros_like(fully_annotated_image, dtype=np.uint8)\n",
    "\n",
    "# Draw filled contours on the mask to represent the areas of white annotation\n",
    "for fully_annotated_contour in fully_annotated_contours:\n",
    "    cv2.drawContours(mask, [fully_annotated_contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "# Apply the mask to the fully annotated image to remove the white annotation from the dog region\n",
    "removed_annotation_image = cv2.bitwise_and(fully_annotated_image, cv2.bitwise_not(mask))\n",
    "\n",
    "# Create the partially annotated image by overlaying the removed annotation image on the original image\n",
    "partially_annotated_image = cv2.add(removed_annotation_image, fully_annotated_image)\n",
    "\n",
    "# Display the partially annotated image\n",
    "cv2.imshow(\"Partially Annotated Image\", partially_annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27cd455a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to load the annotation mask. Please check the file path and format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Check if the annotation mask was loaded successfully\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fully_annotated_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load the annotation mask. Please check the file path and format.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Resize the mask to match the dimensions of the fully annotated image\u001b[39;00m\n\u001b[0;32m     22\u001b[0m resized_mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(fully_annotated_mask, (fully_annotated_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], fully_annotated_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to load the annotation mask. Please check the file path and format."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\fully_annotated_image.jpg'\n",
    "fully_annotated_mask_path = r'path/to/annotation_mask.png'\n",
    "\n",
    "# Load the fully annotated image\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "\n",
    "# Load the annotation mask as grayscale image\n",
    "fully_annotated_mask = cv2.imread(fully_annotated_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if the fully annotated image was loaded successfully\n",
    "if fully_annotated_image is None:\n",
    "    raise ValueError(\"Failed to load the fully annotated image. Please check the file path and format.\")\n",
    "\n",
    "# Check if the annotation mask was loaded successfully\n",
    "if fully_annotated_mask is None:\n",
    "    raise ValueError(\"Failed to load the annotation mask. Please check the file path and format.\")\n",
    "\n",
    "# Resize the mask to match the dimensions of the fully annotated image\n",
    "resized_mask = cv2.resize(fully_annotated_mask, (fully_annotated_image.shape[1], fully_annotated_image.shape[0]))\n",
    "\n",
    "# Threshold the mask to obtain binary segmentation\n",
    "_, fully_annotated_binary_mask = cv2.threshold(resized_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary mask\n",
    "fully_annotated_contours, _ = cv2.findContours(fully_annotated_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate over the fully annotated contours and transfer the annotations to the corresponding regions in the reference image\n",
    "for fully_annotated_contour in fully_annotated_contours:\n",
    "    # Find the bounding rectangle for the fully annotated contour\n",
    "    x, y, w, h = cv2.boundingRect(fully_annotated_contour)\n",
    "\n",
    "    # Extract the corresponding region in the reference image\n",
    "    reference_region = reference_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the annotation or label to the reference region\n",
    "    # You can perform any desired operation here, such as refining boundaries, aligning annotations, or modifying labels\n",
    "\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the reference image\n",
    "    reference_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "# Overlay the transferred and adjusted annotations onto the partially annotated image\n",
    "partially_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\partially_annotated_image.jpg'\n",
    "\n",
    "# Load the partially annotated image\n",
    "partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "\n",
    "# Create a blank image with the same size as the partially annotated image\n",
    "transferred_annotations = np.zeros_like(partially_annotated_image)\n",
    "\n",
    "# Validate the sizes of partially_annotated_image and transferred_annotations\n",
    "if partially_annotated_image.shape[:2] != transferred_annotations.shape[:2]:\n",
    "    raise ValueError(\"Sizes of partially annotated image and transferred annotations do not match\")\n",
    "\n",
    "# Overlay the transferred annotations onto the partially annotated image\n",
    "combined_image = cv2.addWeighted(partially_annotated_image, 1, transferred_annotations, 0.5, 0)\n",
    "\n",
    "# Display or save the combined image\n",
    "cv2.imshow(\"Combined Image\", combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "813eefc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\fully_annotated_image.jpg'\n",
    "reference_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\original_image.jpg'\n",
    "\n",
    "# Load the fully annotated image and the reference image\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "reference_image = cv2.imread(reference_image_path)\n",
    "\n",
    "# Assuming you have annotation masks for the fully annotated image and reference image\n",
    "fully_annotated_mask_path = \"path/to/fully_annotated_mask.png\"\n",
    "reference_mask_path = \"path/to/reference_mask.png\"\n",
    "\n",
    "# Load the annotation masks as grayscale images\n",
    "fully_annotated_mask = cv2.imread(fully_annotated_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "reference_mask = cv2.imread(reference_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Threshold the masks to obtain binary segmentation\n",
    "_, fully_annotated_binary_mask = cv2.threshold(fully_annotated_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "_, reference_binary_mask = cv2.threshold(reference_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary masks\n",
    "fully_annotated_contours, _ = cv2.findContours(fully_annotated_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "reference_contours, _ = cv2.findContours(reference_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate over the fully annotated contours and transfer the annotations to the corresponding regions in the reference image\n",
    "for fully_annotated_contour in fully_annotated_contours:\n",
    "    # Find the bounding rectangle for the fully annotated contour\n",
    "    x, y, w, h = cv2.boundingRect(fully_annotated_contour)\n",
    "\n",
    "    # Extract the corresponding region in the reference image\n",
    "    reference_region = reference_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the annotation or label to the reference region\n",
    "    # You can perform any desired operation here, such as refining boundaries, aligning annotations, or modifying labels\n",
    "\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the reference image\n",
    "    reference_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "# Overlay the transferred and adjusted annotations onto the partially annotated image\n",
    "partially_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\partially annotated image.jpg'\n",
    "transferred_annotations_path = r\"C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\transferred_annotations.jpg\"\n",
    "\n",
    "# Load the partially annotated image and the transferred annotations\n",
    "partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "transferred_annotations = cv2.imread(transferred_annotations_path)\n",
    "\n",
    "# Overlay the transferred annotations onto the partially annotated image\n",
    "combined_image = cv2.addWeighted(partially_annotated_image, 1, transferred_annotations, 0.5, 0)\n",
    "\n",
    "# Display or save the combined image\n",
    "cv2.imshow(\"Combined Image\", combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ca95fcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:230: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m _, fully_annotated_binary_mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(fully_annotated_binary_mask, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Apply the binary mask to the combined image\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m combined_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbitwise_and\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfully_annotated_binary_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Display or save the combined image\u001b[39;00m\n\u001b[0;32m     52\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombined Image\u001b[39m\u001b[38;5;124m\"\u001b[39m, combined_image)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:230: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\fully_annotated_image.jpg'\n",
    "reference_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\original_image.jpg'\n",
    "\n",
    "# Load the fully annotated image and the reference image\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "reference_image = cv2.imread(reference_image_path)\n",
    "\n",
    "# Assuming you have annotation masks for the fully annotated image and reference image\n",
    "fully_annotated_mask_path = \"path/to/fully_annotated_mask.png\"\n",
    "reference_mask_path = \"path/to/reference_mask.png\"\n",
    "\n",
    "# Load the annotation masks as grayscale images\n",
    "fully_annotated_mask = cv2.imread(fully_annotated_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "reference_mask = cv2.imread(reference_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Threshold the masks to obtain binary segmentation\n",
    "_, fully_annotated_binary_mask = cv2.threshold(fully_annotated_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "_, reference_binary_mask = cv2.threshold(reference_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary masks\n",
    "fully_annotated_contours, _ = cv2.findContours(fully_annotated_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "reference_contours, _ = cv2.findContours(reference_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate over the fully annotated contours and transfer the annotations to the corresponding regions in the reference image\n",
    "for fully_annotated_contour in fully_annotated_contours:\n",
    "    # Find the bounding rectangle for the fully annotated contour\n",
    "    x, y, w, h = cv2.boundingRect(fully_annotated_contour)\n",
    "\n",
    "    # Extract the corresponding region in the reference image\n",
    "    reference_region = reference_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the annotation or label to the reference region\n",
    "    # You can perform any desired operation here, such as refining boundaries, aligning annotations, or modifying labels\n",
    "\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the reference image\n",
    "    reference_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "# Create a binary mask from the fully annotated image\n",
    "fully_annotated_binary_mask = cv2.cvtColor(fully_annotated_image, cv2.COLOR_BGR2GRAY)\n",
    "_, fully_annotated_binary_mask = cv2.threshold(fully_annotated_binary_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Apply the binary mask to the combined image\n",
    "combined_image = cv2.bitwise_and(combined_image, combined_image, mask=255 - fully_annotated_binary_mask)\n",
    "\n",
    "# Display or save the combined image\n",
    "cv2.imshow(\"Combined Image\", combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "998b8dfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m combined_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maddWeighted(partially_annotated_image, \u001b[38;5;241m1\u001b[39m, transferred_annotations, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Resize the fully annotated binary mask to match the dimensions of the combined image\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m fully_annotated_binary_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfully_annotated_binary_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Apply the binary mask to the combined image\u001b[39;00m\n\u001b[0;32m     66\u001b[0m combined_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbitwise_and(combined_image, combined_image, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m-\u001b[39m fully_annotated_binary_mask)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\fully_annotated_image.jpg'\n",
    "reference_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\original_image.jpg'\n",
    "\n",
    "# Load the fully annotated image and the reference image\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "reference_image = cv2.imread(reference_image_path)\n",
    "\n",
    "# Assuming you have annotation masks for the fully annotated image and reference image\n",
    "fully_annotated_mask_path = \"path/to/fully_annotated_mask.png\"\n",
    "reference_mask_path = \"path/to/reference_mask.png\"\n",
    "\n",
    "# Load the annotation masks as grayscale images\n",
    "fully_annotated_mask = cv2.imread(fully_annotated_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "reference_mask = cv2.imread(reference_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Threshold the masks to obtain binary segmentation\n",
    "_, fully_annotated_binary_mask = cv2.threshold(fully_annotated_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "_, reference_binary_mask = cv2.threshold(reference_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary masks\n",
    "fully_annotated_contours, _ = cv2.findContours(fully_annotated_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "reference_contours, _ = cv2.findContours(reference_binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate over the fully annotated contours and transfer the annotations to the corresponding regions in the reference image\n",
    "for fully_annotated_contour in fully_annotated_contours:\n",
    "    # Find the bounding rectangle for the fully annotated contour\n",
    "    x, y, w, h = cv2.boundingRect(fully_annotated_contour)\n",
    "\n",
    "    # Extract the corresponding region in the reference image\n",
    "    reference_region = reference_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the annotation or label to the reference region\n",
    "    # You can perform any desired operation here, such as refining boundaries, aligning annotations, or modifying labels\n",
    "\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the reference image\n",
    "    reference_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "# Overlay the transferred and adjusted annotations onto the partially annotated image\n",
    "partially_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\partially annotated image.jpg'\n",
    "transferred_annotations_path = r\"C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\transferred_annotations.jpg\"\n",
    "\n",
    "# Load the partially annotated image and the transferred annotations\n",
    "partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "transferred_annotations = cv2.imread(transferred_annotations_path)\n",
    "\n",
    "# Validate the sizes of partially_annotated_image and transferred_annotations\n",
    "if partially_annotated_image.shape[:2] != transferred_annotations.shape[:2]:\n",
    "    raise ValueError(\"Sizes of partially annotated image and transferred annotations do not match\")\n",
    "\n",
    "# Create a blank image with the same size as the partially annotated image\n",
    "combined_image = np.zeros_like(partially_annotated_image)\n",
    "\n",
    "# Overlay the transferred annotations onto the partially annotated image\n",
    "combined_image = cv2.addWeighted(partially_annotated_image, 1, transferred_annotations, 0.5, 0)\n",
    "\n",
    "# Resize the fully annotated binary mask to match the dimensions of the combined image\n",
    "fully_annotated_binary_mask = cv2.resize(fully_annotated_binary_mask, (combined_image.shape[1], combined_image.shape[0]))\n",
    "\n",
    "# Apply the binary mask to the combined image\n",
    "combined_image = cv2.bitwise_and(combined_image, combined_image, mask=255 - fully_annotated_binary_mask)\n",
    "\n",
    "# Display or save the combined image\n",
    "cv2.imshow(\"Combined Image\", combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "837609a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set the paths to the train and test folders\n",
    "train_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1'\n",
    "test_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\test1'\n",
    "\n",
    "# Load the original, fully annotated, and partially annotated images from the train folder\n",
    "original_image_path = os.path.join(train_folder, 'original_image.jpg')\n",
    "fully_annotated_image_path = os.path.join(train_folder,  'fully_annotated.jpg')\n",
    "partially_annotated_image_path = os.path.join(train_folder, 'partially_annotated.jpg')\n",
    "\n",
    "original_image = cv2.imread(original_image_path)\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "\n",
    "# Assuming the annotations are in the form of bounding boxes\n",
    "# Define the coordinates of the cat and dog annotations in the fully annotated image\n",
    "cat_annotation = [(50, 100, 200, 250)]  # (x, y, width, height)\n",
    "dog_annotation = [(300, 150, 180, 200)]  # (x, y, width, height)\n",
    "\n",
    "# Iterate over the annotations and transfer them to the reference image\n",
    "for annotation in cat_annotation + dog_annotation:\n",
    "    x, y, w, h = annotation\n",
    "\n",
    "    # Extract the corresponding region in the original image\n",
    "    reference_region = original_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the annotation or label to the reference region\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the original image\n",
    "    original_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "# Save the modified original image with transferred annotations\n",
    "modified_original_image_path = os.path.join(train_folder, 'modified_original_image.jpg')\n",
    "cv2.imwrite(modified_original_image_path, original_image)\n",
    "\n",
    "# Load the fully annotated image from the test folder\n",
    "fully_annotated_test_image_path = os.path.join(test_folder, 'fully_annotated', 'fully_annotated.jpg')\n",
    "fully_annotated_test_image = cv2.imread(fully_annotated_test_image_path)\n",
    "\n",
    "# Extract the cat annotation from the fully annotated test image\n",
    "cat_annotation_test = [(50, 100, 200, 250)]  # (x, y, width, height)\n",
    "\n",
    "# Iterate over the cat annotation and transfer it to the partially annotated image\n",
    "for annotation in cat_annotation_test:\n",
    "    x, y, w, h = annotation\n",
    "\n",
    "    # Extract the corresponding region in the partially annotated image\n",
    "    reference_region = partially_annotated_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the cat annotation to the reference region\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the partially annotated image\n",
    "    partially_annotated_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "# Save the modified partially annotated image with the retained cat annotation\n",
    "modified_partially_annotated_image_path = os.path.join(test_folder, 'modified_partially_annotated_image.jpg')\n",
    "cv2.imwrite(modified_partially_annotated_image_path, partially_annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "401f84b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m x, y, w, h \u001b[38;5;241m=\u001b[39m annotation\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Extract the corresponding region in the original image\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m reference_region \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Apply the annotation or label to the reference region\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Example: Draw a red bounding box\u001b[39;00m\n\u001b[0;32m     32\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(reference_region, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (w, h), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the paths to the train and test folders\n",
    "train_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train'\n",
    "test_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\test'\n",
    "\n",
    "# Load the original, fully annotated, and partially annotated images from the train folder\n",
    "original_image_path = os.path.join(train_folder, 'original_image.jpg')\n",
    "fully_annotated_image_path = os.path.join(train_folder, 'fully_annotated.jpg')\n",
    "partially_annotated_image_path = os.path.join(train_folder, 'partially_annotated.jpg')\n",
    "\n",
    "original_image = cv2.imread(original_image_path)\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "\n",
    "# Assuming the annotations are in the form of bounding boxes\n",
    "# Define the coordinates of the cat and dog annotations in the fully annotated image\n",
    "cat_annotation = [(50, 100, 200, 250)]  # (x, y, width, height)\n",
    "dog_annotation = [(300, 150, 180, 200)]  # (x, y, width, height)\n",
    "\n",
    "# Iterate over the annotations and transfer them to the corresponding regions in the images\n",
    "for annotation in cat_annotation + dog_annotation:\n",
    "    x, y, w, h = annotation\n",
    "\n",
    "    # Extract the corresponding region in the original image\n",
    "    reference_region = original_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the annotation or label to the reference region\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the original image\n",
    "    original_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "    # Extract the corresponding region in the partially annotated image\n",
    "    reference_region = partially_annotated_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the annotation or label to the reference region\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the partially annotated image\n",
    "    partially_annotated_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "# Save the modified images\n",
    "modified_original_image_path = os.path.join(train_folder, 'modified_original_image.jpg')\n",
    "cv2.imwrite(modified_original_image_path, original_image)\n",
    "\n",
    "modified_partially_annotated_image_path = os.path.join(train_folder, 'modified_partially_annotated_image.jpg')\n",
    "cv2.imwrite(modified_partially_annotated_image_path, partially_annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d3cceaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the paths to the train and test folders\n",
    "train_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1'\n",
    "test_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\test1'\n",
    "\n",
    "# Load the fully annotated and original images from the test folder\n",
    "fully_annotated_image_path = os.path.join(test_folder, 'fully_annotated.jpg')\n",
    "original_image_path = os.path.join(test_folder, 'original_image.jpg')\n",
    "\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "original_image = cv2.imread(original_image_path)\n",
    "\n",
    "# Assuming the annotations are in the form of bounding boxes\n",
    "# Define the coordinates of the cat annotation in the fully annotated image\n",
    "cat_annotation = [(50, 100, 200, 250)]  # (x, y, width, height)\n",
    "\n",
    "# Create a copy of the fully annotated image to generate the partially annotated image\n",
    "partially_annotated_image = fully_annotated_image.copy()\n",
    "\n",
    "# Iterate over the cat annotation and transfer it to the partially annotated image\n",
    "for annotation in cat_annotation:\n",
    "    x, y, w, h = annotation\n",
    "\n",
    "    # Extract the corresponding region in the original image\n",
    "    reference_region = original_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the cat annotation to the reference region\n",
    "    # Example: Draw a red bounding box\n",
    "    cv2.rectangle(reference_region, (0, 0), (w, h), (0, 0, 255), 2)\n",
    "\n",
    "    # Merge the modified reference region back into the partially annotated image\n",
    "    partially_annotated_image[y:y+h, x:x+w] = reference_region\n",
    "\n",
    "# Save the partially annotated image\n",
    "partially_annotated_image_path = os.path.join(test_folder, 'partially_annotated_image.jpg')\n",
    "cv2.imwrite(partially_annotated_image_path, partially_annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0d16ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the paths to the train and test folders\n",
    "train_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1'\n",
    "test_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\test1'\n",
    "\n",
    "# Load the fully annotated and original images from the test folder\n",
    "fully_annotated_image_path = os.path.join(test_folder, 'fully_annotated.jpg')\n",
    "original_image_path = os.path.join(test_folder, 'original_image.jpg')\n",
    "\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "original_image = cv2.imread(original_image_path)\n",
    "\n",
    "# Assuming the annotations are in the form of bounding boxes\n",
    "# Define the coordinates of the dog annotation in the fully annotated image\n",
    "dog_annotation = [(300, 150, 180, 200)]  # (x, y, width, height)\n",
    "\n",
    "# Create a copy of the fully annotated image to generate the partially annotated image\n",
    "partially_annotated_image = fully_annotated_image.copy()\n",
    "\n",
    "# Iterate over the dog annotation and remove it from the partially annotated image\n",
    "for annotation in dog_annotation:\n",
    "    x, y, w, h = annotation\n",
    "\n",
    "    # Fill the dog annotation region with white color to remove it\n",
    "    partially_annotated_image[y:y+h, x:x+w] = (255, 255, 255)\n",
    "\n",
    "# Save the partially annotated image with the removed dog annotation\n",
    "partially_annotated_image_path = os.path.join(test_folder, 'partially_annotated_image.jpg')\n",
    "cv2.imwrite(partially_annotated_image_path, partially_annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8591ed96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the paths to the train and test folders\n",
    "train_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1'\n",
    "test_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\test1'\n",
    "\n",
    "# Load the fully annotated and original images from the test folder\n",
    "fully_annotated_image_path = os.path.join(test_folder, 'fully_annotated.jpg')\n",
    "original_image_path = os.path.join(test_folder, 'original_image.jpg')\n",
    "\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "original_image = cv2.imread(original_image_path)\n",
    "\n",
    "# Assuming the annotations are in the form of bounding boxes\n",
    "# Define the coordinates of the dog annotation in the fully annotated image\n",
    "dog_annotation = [(300, 150, 180, 200)]  # (x, y, width, height)\n",
    "\n",
    "# Create a copy of the fully annotated image to generate the partially annotated image\n",
    "partially_annotated_image = fully_annotated_image.copy()\n",
    "\n",
    "# Iterate over the dog annotation and remove it from the partially annotated image\n",
    "for annotation in dog_annotation:\n",
    "    x, y, w, h = annotation\n",
    "\n",
    "    # Replace the dog annotation region in the partially annotated image with the corresponding region from the original image\n",
    "    partially_annotated_image[y:y+h, x:x+w] = original_image[y:y+h, x:x+w]\n",
    "\n",
    "# Save the partially annotated image with the removed dog annotation\n",
    "partially_annotated_image_path = os.path.join(test_folder, 'partially_annotated_image.jpg')\n",
    "cv2.imwrite(partially_annotated_image_path, partially_annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1fa559d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the paths to the train and test folders\n",
    "train_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1'\n",
    "test_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\test1'\n",
    "\n",
    "# Load the fully annotated image from the test folder\n",
    "fully_annotated_image_path = os.path.join(test_folder, 'fully_annotated.jpg')\n",
    "\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "\n",
    "# Assuming the annotation is a bounding box of the dog\n",
    "dog_annotation = [(300, 150, 180, 200)]  # (x, y, width, height)\n",
    "\n",
    "# Iterate over the dog annotation and remove it from the fully annotated image\n",
    "for annotation in dog_annotation:\n",
    "    x, y, w, h = annotation\n",
    "\n",
    "    # Set the region of the annotation to the average color of the surrounding pixels\n",
    "    average_color = np.mean(fully_annotated_image[y:y+h, x:x+w], axis=(0, 1))\n",
    "    fully_annotated_image[y:y+h, x:x+w] = average_color.astype(np.uint8)\n",
    "\n",
    "# Save the modified fully annotated image with the removed dog annotation\n",
    "modified_fully_annotated_image_path = os.path.join(test_folder, 'modified_fully_annotated.jpg')\n",
    "cv2.imwrite(modified_fully_annotated_image_path, fully_annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6e71b4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:230: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Use the mask to replace the annotated regions with the corresponding pixels from the original image\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m removed_annotation_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbitwise_and\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfully_annotated_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfully_annotated_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m restored_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbitwise_or(removed_annotation_image, original_image)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Save the modified fully annotated image with the annotations removed\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:230: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the paths to the train and test folders\n",
    "train_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1'\n",
    "test_folder = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\test1'\n",
    "\n",
    "# Load the fully annotated image and original image from the test folder\n",
    "fully_annotated_image_path = os.path.join(test_folder, 'fully_annotated.jpg')\n",
    "original_image_path = os.path.join(test_folder, 'original_image.jpg')\n",
    "\n",
    "fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "original_image = cv2.imread(original_image_path)\n",
    "\n",
    "# Assuming the annotations are white regions, convert the fully annotated image to grayscale\n",
    "gray_image = cv2.cvtColor(fully_annotated_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the grayscale image to obtain the white regions\n",
    "_, threshold = cv2.threshold(gray_image, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Invert the threshold image to get the black regions\n",
    "mask = cv2.bitwise_not(threshold)\n",
    "\n",
    "# Resize the mask to match the image dimensions\n",
    "mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "# Convert the mask to binary (0 or 255) data type\n",
    "mask = mask.astype(np.uint8)\n",
    "\n",
    "# Use the mask to replace the annotated regions with the corresponding pixels from the original image\n",
    "removed_annotation_image = cv2.bitwise_and(fully_annotated_image, fully_annotated_image, mask=mask)\n",
    "restored_image = cv2.bitwise_or(removed_annotation_image, original_image)\n",
    "\n",
    "# Save the modified fully annotated image with the annotations removed\n",
    "modified_fully_annotated_image_path = os.path.join(test_folder, 'modified_fully_annotated.jpg')\n",
    "cv2.imwrite(modified_fully_annotated_image_path, restored_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e8fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_output_image(original_image_path: str, fully_annotated_image_path: str, partially_annotated_image_path: str):\n",
    "    # Load the images\n",
    "    original_image = cv2.imread(original_image_path)\n",
    "    fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "    partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "\n",
    "    # Resize images to match the size of the original image\n",
    "    original_image = cv2.resize(original_image, (fully_annotated_image.shape[1], fully_annotated_image.shape[0]))\n",
    "    partially_annotated_image = cv2.resize(partially_annotated_image, (fully_annotated_image.shape[1], fully_annotated_image.shape[0]))\n",
    "\n",
    "    # Convert the images to grayscale\n",
    "    original_gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "    fully_annotated_gray = cv2.cvtColor(fully_annotated_image, cv2.COLOR_BGR2GRAY)\n",
    "    partially_annotated_gray = cv2.cvtColor(partially_annotated_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Canny edge detection to the fully annotated and partially annotated images\n",
    "    fully_annotated_edges = cv2.Canny(fully_annotated_gray, 100, 200)\n",
    "    partially_annotated_edges = cv2.Canny(partially_annotated_gray, 100, 200)\n",
    "\n",
    "    # Calculate the absolute difference between the edge images\n",
    "    diff = cv2.absdiff(fully_annotated_edges, partially_annotated_edges)\n",
    "\n",
    "    # Threshold the difference image to create a binary mask\n",
    "    _, mask = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY)\n",
    "    mask = np.uint8(mask)\n",
    "\n",
    "    # Invert the mask\n",
    "    inverted_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Apply the inverted mask to the original image\n",
    "    de_annotated_image = cv2.bitwise_and(original_image, original_image, mask=inverted_mask)\n",
    "\n",
    "    # Save the partially de-annotated image\n",
    "    cv2.imwrite(partially_annotated_image_path, de_annotated_image)\n",
    "\n",
    "# Example usage\n",
    "original_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\original_image.jpg'\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\fully_annotated.jpg'\n",
    "partially_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\partially_annotated.jpg'\n",
    "\n",
    "get_output_image(original_image_path, fully_annotated_image_path, partially_annotated_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe63f9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation Box Length: 78\n",
      "Analysis Results:\n",
      "Original Image Dimensions: (978, 978)\n",
      "Fully Annotated Image Dimensions: (938, 939)\n",
      "Partially Annotated Image Dimensions: (978, 978)\n",
      "Annotation Box Length in Fully Annotated Image: 78\n",
      "Annotation Box Length in Partially Annotated Image: 53\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_annotation_box_length(annotation_image_path: str):\n",
    "    # Load the annotation image\n",
    "    annotation_image = cv2.imread(annotation_image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    annotation_gray = cv2.cvtColor(annotation_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(annotation_gray, 100, 200)\n",
    "    \n",
    "    # Find contours in the edge image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the length of the bounding box of the largest contour\n",
    "    if len(contours) > 0:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "        length = max(w, h)\n",
    "        return length\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def analyze_images(original_image_path: str, fully_annotated_image_path: str, partially_annotated_image_path: str):\n",
    "    # Load the images\n",
    "    original_image = cv2.imread(original_image_path)\n",
    "    fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "    partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "    \n",
    "    # Calculate annotation box length for fully annotated image\n",
    "    fully_annotated_length = get_annotation_box_length(fully_annotated_image_path)\n",
    "    \n",
    "    # Calculate annotation box length for partially annotated image\n",
    "    partially_annotated_length = get_annotation_box_length(partially_annotated_image_path)\n",
    "    \n",
    "    # Display the analysis results\n",
    "    print(\"Analysis Results:\")\n",
    "    print(\"Original Image Dimensions:\", original_image.shape[:2])\n",
    "    print(\"Fully Annotated Image Dimensions:\", fully_annotated_image.shape[:2])\n",
    "    print(\"Partially Annotated Image Dimensions:\", partially_annotated_image.shape[:2])\n",
    "    print(\"Annotation Box Length in Fully Annotated Image:\", fully_annotated_length)\n",
    "    print(\"Annotation Box Length in Partially Annotated Image:\", partially_annotated_length)\n",
    "\n",
    "def create_partially_annotated_image(original_image_path: str, fully_annotated_image_path: str, output_image_path: str):\n",
    "    # Load the original and fully annotated images\n",
    "    original_image = cv2.imread(original_image_path)\n",
    "    fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "\n",
    "    # Convert the fully annotated image to grayscale\n",
    "    fully_annotated_gray = cv2.cvtColor(fully_annotated_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform adaptive thresholding to create a binary mask of annotations\n",
    "    _, mask = cv2.threshold(fully_annotated_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Resize the mask to match the size of the original image\n",
    "    mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "    # Convert the mask to a binary image with a single channel\n",
    "    mask = np.uint8(mask)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    partially_annotated_image = cv2.bitwise_and(original_image, original_image, mask=mask)\n",
    "\n",
    "    # Save the partially annotated image\n",
    "    cv2.imwrite(output_image_path, partially_annotated_image)\n",
    "# Example usage\n",
    "\n",
    "# Step 1: Get annotation box length\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\fully_annotated.jpg'\n",
    "annotation_box_length = get_annotation_box_length(fully_annotated_image_path)\n",
    "print(\"Annotation Box Length:\", annotation_box_length)\n",
    "\n",
    "# Step 2: Analyze the images\n",
    "original_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\original_image.jpg'\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\fully_annotated.jpg'\n",
    "partially_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\partially_annotated.jpg'\n",
    "\n",
    "analyze_images(original_image_path, fully_annotated_image_path, partially_annotated_image_path)\n",
    "\n",
    "# Step 3: Create partially annotated image using original and fully annotated image\n",
    "output_image_path =  r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\partially_annotated_image.jpg'\n",
    "create_partially_annotated_image(original_image_path, fully_annotated_image_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32d4ef7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation Box Length: 78\n",
      "Analysis Results:\n",
      "Original Image Dimensions: (978, 978)\n",
      "Fully Annotated Image Dimensions: (938, 939)\n",
      "Partially Annotated Image Dimensions: (978, 978)\n",
      "Annotation Box Length in Fully Annotated Image: 78\n",
      "Annotation Box Length in Partially Annotated Image: 53\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_annotation_box_length(annotation_image_path: str):\n",
    "    # Load the annotation image\n",
    "    annotation_image = cv2.imread(annotation_image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    annotation_gray = cv2.cvtColor(annotation_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(annotation_gray, 100, 200)\n",
    "    \n",
    "    # Find contours in the edge image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the length of the bounding box of the largest contour\n",
    "    if len(contours) > 0:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "        length = max(w, h)\n",
    "        return length\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def analyze_images(original_image_path: str, fully_annotated_image_path: str, partially_annotated_image_path: str):\n",
    "    # Load the images\n",
    "    original_image = cv2.imread(original_image_path)\n",
    "    fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "    partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "    \n",
    "    # Calculate annotation box length for fully annotated image\n",
    "    fully_annotated_length = get_annotation_box_length(fully_annotated_image_path)\n",
    "    \n",
    "    # Calculate annotation box length for partially annotated image\n",
    "    partially_annotated_length = get_annotation_box_length(partially_annotated_image_path)\n",
    "    \n",
    "    # Display the analysis results\n",
    "    print(\"Analysis Results:\")\n",
    "    print(\"Original Image Dimensions:\", original_image.shape[:2])\n",
    "    print(\"Fully Annotated Image Dimensions:\", fully_annotated_image.shape[:2])\n",
    "    print(\"Partially Annotated Image Dimensions:\", partially_annotated_image.shape[:2])\n",
    "    print(\"Annotation Box Length in Fully Annotated Image:\", fully_annotated_length)\n",
    "    print(\"Annotation Box Length in Partially Annotated Image:\", partially_annotated_length)\n",
    "\n",
    "def create_partially_annotated_image(original_image_path, fully_annotated_image_path, output_image_path):\n",
    "    # Load the original and fully annotated images\n",
    "    original_image = cv2.imread(original_image_path)\n",
    "    fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "\n",
    "    # Convert the fully annotated image to grayscale\n",
    "    fully_annotated_gray = cv2.cvtColor(fully_annotated_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform adaptive thresholding to create a binary mask of annotations\n",
    "    _, mask = cv2.threshold(fully_annotated_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Resize the mask to match the size of the original image\n",
    "    mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "    # Invert the mask to represent the regions to be removed\n",
    "    inverted_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Apply the inverted mask to the original image to remove the dog annotation\n",
    "    partially_annotated_image = cv2.bitwise_and(original_image, original_image, mask=inverted_mask)\n",
    "\n",
    "    # Save the partially annotated image\n",
    "    cv2.imwrite(output_image_path, partially_annotated_image)\n",
    "\n",
    "# Step 1: Get annotation box length\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\fully_annotated.jpg'\n",
    "annotation_box_length = get_annotation_box_length(fully_annotated_image_path)\n",
    "print(\"Annotation Box Length:\", annotation_box_length)\n",
    "\n",
    "# Step 2: Analyze the images\n",
    "original_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\original_image.jpg'\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\fully_annotated.jpg'\n",
    "partially_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\partially_annotated.jpg'\n",
    "\n",
    "analyze_images(original_image_path, fully_annotated_image_path, partially_annotated_image_path)\n",
    "\n",
    "# Step 3: Create partially annotated image using original and fully annotated image\n",
    "output_image_path =  r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\partially_annotated_image.jpg'\n",
    "create_partially_annotated_image(original_image_path, fully_annotated_image_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "163ad519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation Box Length: 78\n",
      "Analysis Results:\n",
      "Original Image Dimensions: (978, 978)\n",
      "Fully Annotated Image Dimensions: (938, 939)\n",
      "Partially Annotated Image Dimensions: (978, 978)\n",
      "Annotation Box Length in Fully Annotated Image: 78\n",
      "Annotation Box Length in Partially Annotated Image: 53\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_annotation_box_length(annotation_image_path: str):\n",
    "    # Load the annotation image\n",
    "    annotation_image = cv2.imread(annotation_image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    annotation_gray = cv2.cvtColor(annotation_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(annotation_gray, 100, 200)\n",
    "    \n",
    "    # Find contours in the edge image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the length of the bounding box of the largest contour\n",
    "    if len(contours) > 0:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "        length = max(w, h)\n",
    "        return length\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def analyze_images(original_image_path: str, fully_annotated_image_path: str, partially_annotated_image_path: str):\n",
    "    # Load the images\n",
    "    original_image = cv2.imread(original_image_path)\n",
    "    fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "    partially_annotated_image = cv2.imread(partially_annotated_image_path)\n",
    "    \n",
    "    # Calculate annotation box length for fully annotated image\n",
    "    fully_annotated_length = get_annotation_box_length(fully_annotated_image_path)\n",
    "    \n",
    "    # Calculate annotation box length for partially annotated image\n",
    "    partially_annotated_length = get_annotation_box_length(partially_annotated_image_path)\n",
    "    \n",
    "    # Display the analysis results\n",
    "    print(\"Analysis Results:\")\n",
    "    print(\"Original Image Dimensions:\", original_image.shape[:2])\n",
    "    print(\"Fully Annotated Image Dimensions:\", fully_annotated_image.shape[:2])\n",
    "    print(\"Partially Annotated Image Dimensions:\", partially_annotated_image.shape[:2])\n",
    "    print(\"Annotation Box Length in Fully Annotated Image:\", fully_annotated_length)\n",
    "    print(\"Annotation Box Length in Partially Annotated Image:\", partially_annotated_length)\n",
    "\n",
    "def create_partially_annotated_image(original_image_path: str, fully_annotated_image_path: str, output_image_path: str):\n",
    "    # Load the original and fully annotated images\n",
    "    original_image = cv2.imread(original_image_path)\n",
    "    fully_annotated_image = cv2.imread(fully_annotated_image_path)\n",
    "\n",
    "    # Convert the fully annotated image to grayscale\n",
    "    fully_annotated_gray = cv2.cvtColor(fully_annotated_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform adaptive thresholding to create a binary mask of the annotations\n",
    "    _, mask = cv2.threshold(fully_annotated_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create an empty mask of the same size as the original image\n",
    "    mask = np.zeros(original_image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Iterate over the contours\n",
    "    for contour in contours:\n",
    "        # Calculate the bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Check if the bounding box corresponds to the dog (you can modify this condition based on your annotations)\n",
    "        if w > h:\n",
    "            # Create a rectangular mask for the contour\n",
    "            cv2.drawContours(mask, [contour], 0, 255, cv2.FILLED)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    partially_annotated_image = cv2.bitwise_and(original_image, original_image, mask=mask)\n",
    "\n",
    "    # Save the partially annotated image\n",
    "    cv2.imwrite(output_image_path, partially_annotated_image)\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Get annotation box length\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\fully_annotated.jpg'\n",
    "annotation_box_length = get_annotation_box_length(fully_annotated_image_path)\n",
    "print(\"Annotation Box Length:\", annotation_box_length)\n",
    "\n",
    "# Step 2: Analyze the images\n",
    "original_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\original_image.jpg'\n",
    "fully_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\fully_annotated.jpg'\n",
    "partially_annotated_image_path = r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\partially_annotated.jpg'\n",
    "\n",
    "analyze_images(original_image_path, fully_annotated_image_path, partially_annotated_image_path)\n",
    "\n",
    "# Step 3: Create partially annotated image using original and fully annotated image\n",
    "output_image_path =  r'C:\\Users\\HP\\Downloads\\Computer_vision_assignment_\\train1\\partially_annotated_image.jpg'\n",
    "create_partially_annotated_image(original_image_path, fully_annotated_image_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd0f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e596b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
